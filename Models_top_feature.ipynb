{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "943f81b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score, roc_auc_score, roc_curve\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c520cda4",
   "metadata": {},
   "source": [
    "# Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "083bb457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the training dataset from 'train_df.csv' into a DataFrame\n",
    "train_df = pd.read_csv('train_df.csv')\n",
    "\n",
    "# Read the test dataset from 'test_df.csv' into a DataFrame\n",
    "test_df = pd.read_csv('test_df.csv')\n",
    "\n",
    "# Read the validation dataset from 'val_df.csv' into a DataFrame\n",
    "val_df = pd.read_csv('val_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a30099e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selected Features (Top 10):\n",
    "important_column_10= [\n",
    "    'Age Group', 'Num of Bad Mental Health Days', 'Hours of Sleeping', \n",
    "    'Arthritis', 'Days Drinking', 'Pneumonia Vaccine', 'Tetanus Last 10 Years', \n",
    "    'Income', 'BMI', 'Ethnicity_White', 'Cancer'\n",
    "    ]\n",
    "# Select the important columns for RFE from the training, testing, and validation DataFrames\n",
    "train_df_10 = train_df[important_column_10]\n",
    "test_df_10=  test_df[important_column_10]\n",
    "val_df_10 = val_df[important_column_10]\n",
    "\n",
    "# Separate the features and target variable from the training dataset\n",
    "X_train_10= train_df_10.drop('Cancer', axis=1)\n",
    "y_train_10 = train_df_10['Cancer']\n",
    "\n",
    "# Separate the features and target variable from the testing dataset\n",
    "X_test_10= test_df_10.drop('Cancer', axis=1)\n",
    "y_test_10 = test_df_10['Cancer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e7ee01ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selected Features (Top 20):\n",
    "important_column_20 = [\n",
    "    'Gender', 'Age Group', 'Num of Bad Mental Health Days', 'Years Since Last Checkup', \n",
    "    'Hours of Sleeping', 'Arthritis', 'Married', 'Deaf', 'Age Started Smoking', \n",
    "    'Cigarettes per Day', 'Days Drinking', 'Flu Vaccine', 'Pneumonia Vaccine', \n",
    "    'Tetanus Last 10 Years', 'Had COVID', 'Metropolitan', 'Income', 'Insulin', \n",
    "    'BMI', 'Ethnicity_White', 'Cancer'\n",
    "]\n",
    "# Select the important columns for RFE from the training, testing, and validation DataFrames\n",
    "train_df_20 = train_df[important_column_20]\n",
    "test_df_20=  test_df[important_column_20]\n",
    "val_df_20 = val_df[important_column_20]\n",
    "\n",
    "# Separate the features and target variable from the training dataset\n",
    "X_train_20= train_df_20.drop('Cancer', axis=1)\n",
    "y_train_20 = train_df_20['Cancer']\n",
    "\n",
    "# Separate the features and target variable from the testing dataset\n",
    "X_test_20= test_df_20.drop('Cancer', axis=1)\n",
    "y_test_20 = test_df_20['Cancer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4cb7c3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selected Features (Top 30):\n",
    "important_column_30 = [\n",
    "    'Gender', 'Age Group', 'Num of Bad Mental Health Days',\n",
    "    'Years Since Last Checkup', 'Exercise in Past 30 Days',\n",
    "    'Hours of Sleeping', 'Heart Disease', 'Asthma', 'Depression',\n",
    "    'Kidney Disease', 'Arthritis', 'Diabetes', 'Married', 'Deaf', 'Blind',\n",
    "    'Age Started Smoking', 'Cigarettes per Day', 'Days Drinking',\n",
    "    'Flu Vaccine', 'Pneumonia Vaccine', 'Tetanus Last 10 Years',\n",
    "    'Had COVID', 'Metropolitan', 'Income', 'Insulin', 'BMI',\n",
    "    'Ethnicity_Hispanic', 'Ethnicity_White', 'Education_attended_college',\n",
    "    'Education_graduated_college', 'Cancer'\n",
    "]\n",
    "\n",
    "# Select the important columns for RFE from the training, testing, and validation DataFrames\n",
    "train_df_30 = train_df[important_column_30]\n",
    "test_df_30=  test_df[important_column_30]\n",
    "val_df_30 = val_df[important_column_30]\n",
    "\n",
    "# Separate the features and target variable from the training dataset\n",
    "X_train_30= train_df_30.drop('Cancer', axis=1)\n",
    "y_train_30 = train_df_30['Cancer']\n",
    "\n",
    "# Separate the features and target variable from the testing dataset\n",
    "X_test_30= test_df_30.drop('Cancer', axis=1)\n",
    "y_test_30 = test_df_30['Cancer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "85517cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the features and target variable from the training dataset\n",
    "X_train_41= train_df.drop('Cancer', axis=1)\n",
    "y_train_41 = train_df['Cancer']\n",
    "\n",
    "# Separate the features and target variable from the testing dataset\n",
    "X_test_41= test_df.drop('Cancer', axis=1)\n",
    "y_test_41 = test_df['Cancer']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a8e57a",
   "metadata": {},
   "source": [
    "Functions to create Gaussian Naive Bayes, Support Vector Machine, and Random Forest models with specified parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1ed39647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create and return a Gaussian Naive Bayes model with specified var_smoothing parameter\n",
    "def nb_model():\n",
    "    model = GaussianNB(var_smoothing=3.125)\n",
    "    return model\n",
    "\n",
    "# Function to create and return a Support Vector Machine model using SGDClassifier with specified parameters\n",
    "def svm_model():\n",
    "    model = SGDClassifier(\n",
    "        loss='hinge',            # Hinge loss for SVM\n",
    "        penalty='l2',            # L2 regularization\n",
    "        learning_rate='adaptive', # Adaptive learning rate\n",
    "        alpha=0.5,               # Regularization term\n",
    "        eta0=0.025,              # Initial learning rate\n",
    "        random_state=42          # Seed for reproducibility\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Function to create and return a Random Forest model with specified parameters\n",
    "def rf_model():\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=30,         # Number of trees in the forest\n",
    "        criterion='gini',        # Function to measure the quality of a split\n",
    "        max_depth=3,             # Maximum depth of the tree\n",
    "        random_state=42          # Seed for reproducibility\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb33ae4",
   "metadata": {},
   "source": [
    "Function to perform cross-validation with SMOTE on a given model, returning average accuracy, recall, precision, and F1 scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9e465173",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_scores(model, X, y, cv_folds=5):\n",
    "    \"\"\"\n",
    "    Perform cross-validation on the given model using SMOTE to handle class imbalance and return the average scores.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The machine learning model to evaluate.\n",
    "    - X: The feature set.\n",
    "    - y: The target variable.\n",
    "    - cv_folds: The number of cross-validation folds (default is 5).\n",
    "\n",
    "    Returns:\n",
    "    A dictionary containing the average accuracy, recall, precision, and F1 scores from the cross-validation.\n",
    "    \"\"\"\n",
    "    smote = SMOTE(random_state=42)\n",
    "\n",
    "    # Apply SMOTE to the training data to handle class imbalance\n",
    "    X, y = smote.fit_resample(X, y)\n",
    "\n",
    "    # Define the scoring metrics for cross-validation\n",
    "    scoring = ['recall_macro', 'accuracy', 'precision_macro', 'f1_macro']\n",
    "\n",
    "    # Perform cross-validation and obtain the scores\n",
    "    scores = cross_validate(model, X, y, cv=cv_folds, scoring=scoring)\n",
    "    \n",
    "    # Calculate and return the average scores\n",
    "    return print(f'accuracy: {np.mean(scores[\"test_accuracy\"]):.2f}\\n'\n",
    "             f'recall: {np.mean(scores[\"test_recall_macro\"]):.2f}\\n'\n",
    "             f'precision: {np.mean(scores[\"test_precision_macro\"]):.2f}\\n'\n",
    "             f'f1: {np.mean(scores[\"test_f1_macro\"]):.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d0971f",
   "metadata": {},
   "source": [
    "Functions to perform cross-validation using Gaussian Naive Bayes, Support Vector Machine, and Random Forest models, returning average evaluation metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d822b300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_naive_bayes(X, y, cv_folds=5):\n",
    "    \"\"\"\n",
    "    Perform cross-validation using a Gaussian Naive Bayes model.\n",
    "    \n",
    "    Parameters:\n",
    "    - X: The feature set.\n",
    "    - y: The target variable.\n",
    "    - cv_folds: The number of cross-validation folds (default is 3).\n",
    "    \n",
    "    Returns:\n",
    "    A dictionary containing the average accuracy, recall, precision, and F1 scores.\n",
    "    \"\"\"\n",
    "    model = nb_model() \n",
    "    return cross_validation_scores(model, X, y, cv_folds)\n",
    "\n",
    "def cross_validate_svm(X, y, cv_folds=5):\n",
    "    \"\"\"\n",
    "    Perform cross-validation using a Support Vector Machine (SGDClassifier) model.\n",
    "    \n",
    "    Parameters:\n",
    "    - X: The feature set.\n",
    "    - y: The target variable.\n",
    "    - cv_folds: The number of cross-validation folds (default is 5).\n",
    "    \n",
    "    Returns:\n",
    "    A dictionary containing the average accuracy, recall, precision, and F1 scores.\n",
    "    \"\"\"\n",
    "    sgdc = svm_model() \n",
    "    return cross_validation_scores(sgdc, X, y, cv_folds)\n",
    "\n",
    "def cross_validate_random_forest(X, y, cv_folds=5):\n",
    "    \"\"\"\n",
    "    Perform cross-validation using a Random Forest model.\n",
    "    \n",
    "    Parameters:\n",
    "    - X: The feature set.\n",
    "    - y: The target variable.\n",
    "    - cv_folds: The number of cross-validation folds (default is 5).\n",
    "    \n",
    "    Returns:\n",
    "    A dictionary containing the average accuracy, recall, precision, and F1 scores.\n",
    "    \"\"\"\n",
    "    model = rf_model()\n",
    "    return cross_validation_scores(model, X, y, cv_folds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12f4cc6",
   "metadata": {},
   "source": [
    "Function to evaluate a machine learning model using SMOTE, calculating and returning accuracy, recall, precision, and F1 scores for both training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c6730632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate the performance of a Naive Bayes model using SMOTE to handle class imbalance.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The Naive Bayes model to evaluate.\n",
    "    - X_train: The training feature set.\n",
    "    - y_train: The training target variable.\n",
    "    - X_test: The testing feature set.\n",
    "    - y_test: The testing target variable.\n",
    "\n",
    "    Returns:\n",
    "    A string representation of the model's performance metrics: accuracy, recall, precision, and F1 score for both training and testing sets.\n",
    "    \"\"\"\n",
    "    # Initialize SMOTE with a random state for reproducibility\n",
    "    smote = SMOTE(random_state=42)\n",
    "\n",
    "    # Apply SMOTE to the training data to handle class imbalance\n",
    "    X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Fit the model on the resampled training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the target variable for the training set\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    \n",
    "    # Predict the target variable for the test set\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate evaluation metrics for the training set\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_recall = recall_score(y_train, y_train_pred)\n",
    "    train_precision = precision_score(y_train, y_train_pred)\n",
    "    train_f1 = f1_score(y_train, y_train_pred)\n",
    "    \n",
    "    # Calculate evaluation metrics for the test set\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    test_recall = recall_score(y_test, y_test_pred)\n",
    "    test_precision = precision_score(y_test, y_test_pred)\n",
    "    test_f1 = f1_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Print and return the evaluation metrics\n",
    "    model_scores = print(\n",
    "        f'Training Scores: \\n'\n",
    "        f'Accuracy: {train_accuracy:.2f} \\n'\n",
    "        f'Recall: {train_recall:.2f}\\n'\n",
    "        f'Precision: {train_precision:.2f}\\n'\n",
    "        f'F1: {train_f1:.2f}\\n\\n'\n",
    "        f'Test Scores:\\n'\n",
    "        f'Accuracy: {test_accuracy:.2f}\\n'\n",
    "        f'Recall: {test_recall:.2f}\\n'\n",
    "        f'Precision: {test_precision:.2f}\\n'\n",
    "        f'F1: {test_f1:.2f}\\n'\n",
    "    )\n",
    "    #print(model_scores)\n",
    "    return model_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f46f3a4",
   "metadata": {},
   "source": [
    "# Evaluating Models with Different Numbers of Selected Features\n",
    "This evaluates the performance of three machine learning models (Naive Bayes, Random Forest, and Support Vector Machine) on datasets with different numbers of top selected features (10, 20, 30, and 41). For each set of selected features, the script prints the train and test scores (accuracy, recall, precision, and F1 score) for each model. The models are evaluated using a custom `evaluate_model` function that incorporates SMOTE to handle class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "aef20b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Naive Bayes, Random Forest, and Support Vector Machine models\n",
    "model_nb = nb_model()\n",
    "model_rf = rf_model()\n",
    "model_svm = svm_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "78ad163b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Selected Features \n",
      "\n",
      "NB performance\n",
      "\n",
      "Training Scores: \n",
      "Accuracy: 0.69 \n",
      "Recall: 0.83\n",
      "Precision: 0.65\n",
      "F1: 0.73\n",
      "\n",
      "Test Scores:\n",
      "Accuracy: 0.58\n",
      "Recall: 0.83\n",
      "Precision: 0.19\n",
      "F1: 0.31\n",
      "\n",
      "\n",
      "RF performance\n",
      "\n",
      "Training Scores: \n",
      "Accuracy: 0.71 \n",
      "Recall: 0.82\n",
      "Precision: 0.67\n",
      "F1: 0.74\n",
      "\n",
      "Test Scores:\n",
      "Accuracy: 0.59\n",
      "Recall: 0.81\n",
      "Precision: 0.19\n",
      "F1: 0.31\n",
      "\n",
      "\n",
      "SMV performance\n",
      "\n",
      "Training Scores: \n",
      "Accuracy: 0.69 \n",
      "Recall: 0.85\n",
      "Precision: 0.64\n",
      "F1: 0.73\n",
      "\n",
      "Test Scores:\n",
      "Accuracy: 0.57\n",
      "Recall: 0.84\n",
      "Precision: 0.19\n",
      "F1: 0.31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate models with the top 10 selected features\n",
    "print('Top 10 Selected Features ')\n",
    "\n",
    "print('\\nNB performance\\n')\n",
    "model_nb = nb_model()\n",
    "evaluate_model(model_nb, X_train_10, y_train_10, X_test_10, y_test_10)\n",
    "\n",
    "print('\\nRF performance\\n')\n",
    "model_rf = rf_model()\n",
    "evaluate_model(model_rf, X_train_10, y_train_10, X_test_10, y_test_10)\n",
    "\n",
    "print('\\nSMV performance\\n')\n",
    "model_svm = svm_model()\n",
    "evaluate_model(model_svm, X_train_10, y_train_10, X_test_10, y_test_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "40574307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Selected Features \n",
      "\n",
      "NB performance\n",
      "\n",
      "Training Scores: \n",
      "Accuracy: 0.69 \n",
      "Recall: 0.87\n",
      "Precision: 0.64\n",
      "F1: 0.73\n",
      "\n",
      "Test Scores:\n",
      "Accuracy: 0.54\n",
      "Recall: 0.86\n",
      "Precision: 0.18\n",
      "F1: 0.30\n",
      "\n",
      "\n",
      "RF performance\n",
      "\n",
      "Training Scores: \n",
      "Accuracy: 0.72 \n",
      "Recall: 0.77\n",
      "Precision: 0.70\n",
      "F1: 0.74\n",
      "\n",
      "Test Scores:\n",
      "Accuracy: 0.67\n",
      "Recall: 0.70\n",
      "Precision: 0.21\n",
      "F1: 0.32\n",
      "\n",
      "\n",
      "SMV performance\n",
      "\n",
      "Training Scores: \n",
      "Accuracy: 0.70 \n",
      "Recall: 0.85\n",
      "Precision: 0.65\n",
      "F1: 0.74\n",
      "\n",
      "Test Scores:\n",
      "Accuracy: 0.58\n",
      "Recall: 0.84\n",
      "Precision: 0.19\n",
      "F1: 0.31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate models with the top 20 selected features\n",
    "print('Top 20 Selected Features ')\n",
    "\n",
    "print('\\nNB performance\\n')\n",
    "evaluate_model(model_nb, X_train_20, y_train_20, X_test_20, y_test_20)\n",
    "\n",
    "print('\\nRF performance\\n')\n",
    "evaluate_model(model_rf, X_train_20, y_train_20, X_test_20, y_test_20)\n",
    "\n",
    "print('\\nSMV performance\\n')\n",
    "evaluate_model(model_svm, X_train_20, y_train_20, X_test_20, y_test_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c579a155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 30 Selected Features \n",
      "\n",
      "NB performance\n",
      "\n",
      "Training Scores: \n",
      "Accuracy: 0.68 \n",
      "Recall: 0.88\n",
      "Precision: 0.63\n",
      "F1: 0.74\n",
      "\n",
      "Test Scores:\n",
      "Accuracy: 0.53\n",
      "Recall: 0.87\n",
      "Precision: 0.18\n",
      "F1: 0.30\n",
      "\n",
      "\n",
      "RF performance\n",
      "\n",
      "Training Scores: \n",
      "Accuracy: 0.74 \n",
      "Recall: 0.81\n",
      "Precision: 0.70\n",
      "F1: 0.75\n",
      "\n",
      "Test Scores:\n",
      "Accuracy: 0.65\n",
      "Recall: 0.73\n",
      "Precision: 0.21\n",
      "F1: 0.32\n",
      "\n",
      "\n",
      "SMV performance\n",
      "\n",
      "Training Scores: \n",
      "Accuracy: 0.70 \n",
      "Recall: 0.85\n",
      "Precision: 0.65\n",
      "F1: 0.74\n",
      "\n",
      "Test Scores:\n",
      "Accuracy: 0.58\n",
      "Recall: 0.84\n",
      "Precision: 0.19\n",
      "F1: 0.31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate models with the top 30 selected features\n",
    "print('Top 30 Selected Features ')\n",
    "print('\\nNB performance\\n')\n",
    "evaluate_model(model_nb, X_train_30, y_train_30, X_test_30, y_test_30)\n",
    "\n",
    "print('\\nRF performance\\n')\n",
    "evaluate_model(model_rf, X_train_30, y_train_30, X_test_30, y_test_30)\n",
    "\n",
    "print('\\nSMV performance\\n')\n",
    "evaluate_model(model_svm, X_train_30, y_train_30, X_test_30, y_test_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "865b3cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 41 Selected Features\n",
      "\n",
      "NB performance\n",
      "\n",
      "Training Scores: \n",
      "Accuracy: 0.68 \n",
      "Recall: 0.90\n",
      "Precision: 0.62\n",
      "F1: 0.74\n",
      "\n",
      "Test Scores:\n",
      "Accuracy: 0.51\n",
      "Recall: 0.89\n",
      "Precision: 0.17\n",
      "F1: 0.29\n",
      "\n",
      "\n",
      "RF performance\n",
      "Training Scores: \n",
      "Accuracy: 0.74 \n",
      "Recall: 0.76\n",
      "Precision: 0.72\n",
      "F1: 0.74\n",
      "\n",
      "Test Scores:\n",
      "Accuracy: 0.69\n",
      "Recall: 0.65\n",
      "Precision: 0.22\n",
      "F1: 0.33\n",
      "\n",
      "\n",
      "SMV performance\n",
      "Training Scores: \n",
      "Accuracy: 0.70 \n",
      "Recall: 0.85\n",
      "Precision: 0.65\n",
      "F1: 0.74\n",
      "\n",
      "Test Scores:\n",
      "Accuracy: 0.58\n",
      "Recall: 0.84\n",
      "Precision: 0.19\n",
      "F1: 0.31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate models with the top 41 selected features\n",
    "print('Top 41 Selected Features')\n",
    "print('\\nNB performance\\n')\n",
    "evaluate_model(model_nb, X_train_41, y_train_41, X_test_41, y_test_41)\n",
    "\n",
    "print('\\nRF performance')\n",
    "evaluate_model(model_rf, X_train_41, y_train_41, X_test_41, y_test_41)\n",
    "\n",
    "print('\\nSMV performance')\n",
    "evaluate_model(model_svm, X_train_41, y_train_41, X_test_41, y_test_41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bd936bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Selected Features \n",
      "\n",
      "NB cross validation scores\n",
      "accuracy: 0.69\n",
      "recall: 0.69\n",
      "precision: 0.71\n",
      "f1: 0.68\n",
      "\n",
      "SVM cross validation scores\n",
      "accuracy: 0.69\n",
      "recall: 0.69\n",
      "precision: 0.71\n",
      "f1: 0.68\n",
      "\n",
      "RF cross validation scores\n",
      "accuracy: 0.71\n",
      "recall: 0.71\n",
      "precision: 0.72\n",
      "f1: 0.71\n"
     ]
    }
   ],
   "source": [
    "print('Top 10 Selected Features ')\n",
    "\n",
    "print('\\nNB cross validation scores')\n",
    "cross_validate_naive_bayes(X_train_10, y_train_10)\n",
    "\n",
    "print('\\nSVM cross validation scores')\n",
    "cross_validate_svm(X_train_10, y_train_10)\n",
    "\n",
    "print('\\nRF cross validation scores')\n",
    "cross_validate_random_forest(X_train_10, y_train_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3f0aae34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Selected Features \n",
      "\n",
      "NB cross validation scores\n",
      "accuracy: 0.69\n",
      "recall: 0.69\n",
      "precision: 0.71\n",
      "f1: 0.68\n",
      "\n",
      "SVM cross validation scores\n",
      "accuracy: 0.70\n",
      "recall: 0.70\n",
      "precision: 0.72\n",
      "f1: 0.69\n",
      "\n",
      "RF cross validation scores\n",
      "accuracy: 0.72\n",
      "recall: 0.72\n",
      "precision: 0.73\n",
      "f1: 0.72\n"
     ]
    }
   ],
   "source": [
    "print('Top 20 Selected Features ')\n",
    "\n",
    "print('\\nNB cross validation scores')\n",
    "cross_validate_naive_bayes(X_train_20, y_train_20)\n",
    "\n",
    "print('\\nSVM cross validation scores')\n",
    "cross_validate_svm(X_train_20, y_train_20)\n",
    "\n",
    "print('\\nRF cross validation scores')\n",
    "cross_validate_random_forest(X_train_20, y_train_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "446b1dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 30 Selected Features \n",
      "\n",
      "NB cross validation scores\n",
      "accuracy: 0.68\n",
      "recall: 0.68\n",
      "precision: 0.72\n",
      "f1: 0.67\n",
      "\n",
      "SVM cross validation scores\n",
      "accuracy: 0.70\n",
      "recall: 0.70\n",
      "precision: 0.72\n",
      "f1: 0.69\n",
      "\n",
      "RF cross validation scores\n",
      "accuracy: 0.73\n",
      "recall: 0.73\n",
      "precision: 0.74\n",
      "f1: 0.73\n"
     ]
    }
   ],
   "source": [
    "print('Top 30 Selected Features ')\n",
    "\n",
    "print('\\nNB cross validation scores')\n",
    "cross_validate_naive_bayes(X_train_30, y_train_30)\n",
    "\n",
    "print('\\nSVM cross validation scores')\n",
    "cross_validate_svm(X_train_30, y_train_30)\n",
    "\n",
    "print('\\nRF cross validation scores')\n",
    "cross_validate_random_forest(X_train_30, y_train_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e278bd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 41 Selected Features \n",
      "\n",
      "NB cross validation scores\n",
      "accuracy: 0.68\n",
      "recall: 0.68\n",
      "precision: 0.72\n",
      "f1: 0.66\n",
      "\n",
      "SVM cross validation scores\n",
      "accuracy: 0.70\n",
      "recall: 0.70\n",
      "precision: 0.72\n",
      "f1: 0.69\n",
      "\n",
      "RF cross validation scores\n",
      "accuracy: 0.73\n",
      "recall: 0.73\n",
      "precision: 0.73\n",
      "f1: 0.73\n"
     ]
    }
   ],
   "source": [
    "print('Top 41 Selected Features ')\n",
    "\n",
    "print('\\nNB cross validation scores')\n",
    "cross_validate_naive_bayes(X_train_41, y_train_41)\n",
    "\n",
    "print('\\nSVM cross validation scores')\n",
    "cross_validate_svm(X_train_41, y_train_41)\n",
    "\n",
    "print('\\nRF cross validation scores')\n",
    "cross_validate_random_forest(X_train_41, y_train_41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ac0cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
