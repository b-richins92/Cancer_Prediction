{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3eb631fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "#import statsmodels.api as sm\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score, roc_auc_score, roc_curve\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.metrics import recall_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31dbe634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    train_df= pd.read_csv('train_df.csv')\n",
    "    test_df = pd.read_csv('test_df.csv')\n",
    "    val_df = pd.read_csv('val_df.csv')\n",
    "    return train_df, test_df, val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d3e5a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df, val_df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af08539c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train =train_df.drop('Cancer', axis=1)\n",
    "y_train = train_df['Cancer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8f68484",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "X_train, y_train= smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e621b51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df.drop('Cancer', axis = 1)\n",
    "y_test = test_df['Cancer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6081e798",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = val_df.drop('Cancer', axis = 1)\n",
    "y_val = val_df['Cancer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "240360ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the dataset\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34c49e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Validation Recall: 74.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7453749751342749"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the model\n",
    "def create_model(input_shape, hidden_units, activation):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.InputLayer(input_shape=input_shape))\n",
    "    for units in hidden_units:\n",
    "        model.add(layers.Dense(units, activation=activation, kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "input_shape = X_train.shape[1]\n",
    "hidden_units = [256]  # You can add more units or layers if needed\n",
    "activation = 'relu'\n",
    "model = create_model(input_shape, hidden_units, activation)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1e-4),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Function to evaluate the model based on recall\n",
    "def eval_model(model, X_val, y_val):\n",
    "    y_pred = (model.predict(X_val) > 0.48).astype(\"int32\")\n",
    "    recall = recall_score(y_val, y_pred)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision = precision_score(y_val, y_pred)\n",
    "    f1= f1_score(y_val, y_pred)\n",
    "    model = print(f'Recall: {recall}, Accuracy: {accuracy}, Precision: {precision}, F1_score: {f1}')\n",
    "    return model\n",
    "\n",
    "# Training and evaluating the model to choose the best one based on recall\n",
    "best_recall = 0\n",
    "best_model = None\n",
    "\n",
    "for i in range(30):\n",
    "    model = create_model(input_shape, hidden_units, activation)\n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1e-4),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=5, batch_size=50, validation_data=(X_val, y_val), verbose=0)\n",
    "    \n",
    "    current_recall = eval_model(model, X_val, y_val)\n",
    "    if current_recall > best_recall:\n",
    "        best_recall = current_recall\n",
    "        best_model = tf.keras.models.clone_model(model)\n",
    "        best_model.set_weights(model.get_weights())\n",
    "\n",
    "print(f'Best Validation Recall: {best_recall * 100:.2f}%')\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "eval_model(best_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c2fd780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.7453749751342749.2f, Accuracy: 0.6483556198048428, Precision: 0.2077626836706404, F1_score: 0.32495013442025844\n"
     ]
    }
   ],
   "source": [
    "# Function to evaluate the model based on recall\n",
    "def eval_model(model, X_val, y_val):\n",
    "    y_pred = (model.predict(X_val) > 0.48).astype(\"int32\")\n",
    "    recall = recall_score(y_val, y_pred)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision = precision_score(y_val, y_pred)\n",
    "    f1= f1_score(y_val, y_pred)\n",
    "    model = print(f'Recall: {recall}, Accuracy: {accuracy}, Precision: {precision}, F1_score: {f1}')\n",
    "    return model\n",
    "# Evaluate the best model on the test set\n",
    "eval_model(best_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fcfbe35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "19623/19623 [==============================] - 21s 1ms/step - loss: 0.4991 - recall_1: 0.7916\n",
      "Epoch 2/10\n",
      "19623/19623 [==============================] - 21s 1ms/step - loss: 0.4414 - recall_1: 0.7946\n",
      "Epoch 3/10\n",
      "19623/19623 [==============================] - 29s 1ms/step - loss: 0.4199 - recall_1: 0.7957\n",
      "Epoch 4/10\n",
      "19623/19623 [==============================] - 31s 2ms/step - loss: 0.4061 - recall_1: 0.7955\n",
      "Epoch 5/10\n",
      "19623/19623 [==============================] - 28s 1ms/step - loss: 0.3983 - recall_1: 0.7961\n",
      "Epoch 6/10\n",
      "19623/19623 [==============================] - 34s 2ms/step - loss: 0.3924 - recall_1: 0.7961\n",
      "Epoch 7/10\n",
      "19623/19623 [==============================] - 34s 2ms/step - loss: 0.3881 - recall_1: 0.7959\n",
      "Epoch 8/10\n",
      "19623/19623 [==============================] - 34s 2ms/step - loss: 0.3850 - recall_1: 0.7972\n",
      "Epoch 9/10\n",
      "19623/19623 [==============================] - 34s 2ms/step - loss: 0.3821 - recall_1: 0.7979\n",
      "Epoch 10/10\n",
      "19623/19623 [==============================] - 34s 2ms/step - loss: 0.3799 - recall_1: 0.7981\n",
      "1384/1384 - 2s - loss: 0.4589 - recall_1: 0.3935 - 2s/epoch - 1ms/step\n",
      "Test recall: 0.3934752345085144\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the neural network architecture\n",
    "model = models.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')  # Binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=[tf.keras.metrics.Recall()])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_recall = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f'Test recall: {test_recall}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cff14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self,num_inputs=784,num_outputs=10,num_hiddens=256, activate = \"ReLU\"):\n",
    "        super(MLP, self).__init__()\n",
    "        ## TODO: Build your MLP network, feel free to add more arguments to the init function if needed.\n",
    "        # YOUR CODE HERE\n",
    "        self.activate = nn.ReLU() if activate == \"ReLU\" else nn.Tanh() if activate == \"Tanh\" else nn.Sigmoid()\n",
    "        self.layer1 = nn.Linear(num_inputs, num_hiddens)\n",
    "        self.layer2 = nn.Linear(num_hiddens, num_outputs)\n",
    "        \n",
    "        #raise NotImplementedError()\n",
    "\n",
    "    def forward(self, X):\n",
    "        ## TODO: feed data into the MLP network that you built.\n",
    "    \n",
    "        #raise NotImplementedError()\n",
    "        X = X.view(-1, 28*28)\n",
    "        X = self.activate(self.layer1(X))\n",
    "        X = self.activate(self.layer2(X))\n",
    "        \n",
    "        \n",
    "        return X\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a42eb3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.0: 211343, 1.0: 211343}\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "435a1f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6605/6605 [==============================] - 15s 2ms/step - loss: 0.5687 - recall_2: 0.7935 - accuracy: 0.7003\n",
      "Epoch 2/10\n",
      "6605/6605 [==============================] - 14s 2ms/step - loss: 0.5296 - recall_2: 0.8008 - accuracy: 0.7247\n",
      "Epoch 3/10\n",
      "6605/6605 [==============================] - 14s 2ms/step - loss: 0.5033 - recall_2: 0.7943 - accuracy: 0.7371\n",
      "Epoch 4/10\n",
      "6605/6605 [==============================] - 14s 2ms/step - loss: 0.4980 - recall_2: 0.7929 - accuracy: 0.7397\n",
      "Epoch 5/10\n",
      "6605/6605 [==============================] - 14s 2ms/step - loss: 0.4961 - recall_2: 0.7929 - accuracy: 0.7408\n",
      "Epoch 6/10\n",
      "6605/6605 [==============================] - 14s 2ms/step - loss: 0.4938 - recall_2: 0.7945 - accuracy: 0.7417\n",
      "Epoch 7/10\n",
      "6605/6605 [==============================] - 14s 2ms/step - loss: 0.4928 - recall_2: 0.7960 - accuracy: 0.7430\n",
      "Epoch 8/10\n",
      "6605/6605 [==============================] - 14s 2ms/step - loss: 0.4907 - recall_2: 0.7965 - accuracy: 0.7442\n",
      "Epoch 9/10\n",
      "6605/6605 [==============================] - 14s 2ms/step - loss: 0.4892 - recall_2: 0.7986 - accuracy: 0.7450\n",
      "Epoch 10/10\n",
      "6605/6605 [==============================] - 13s 2ms/step - loss: 0.4877 - recall_2: 0.8001 - accuracy: 0.7465\n",
      "1883/1883 - 3s - loss: 0.5152 - recall_2: 0.6153 - accuracy: 0.6978 - 3s/epoch - 1ms/step\n",
      "Test recall: 0.6153319478034973\n",
      "Test accuracy: 0.6977519989013672\n",
      "Test F1 score: 0.3305754734326163\n"
     ]
    }
   ],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the neural network architecture\n",
    "model = models.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')  \n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=[tf.keras.metrics.Recall(), 'accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_recall, test_accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f'Test recall: {test_recall}')\n",
    "print(f'Test accuracy: {test_accuracy}')\n",
    "\n",
    "# Predict on test data to calculate F1 score\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Calculate F1 score\n",
    "test_f1 = f1_score(y_test, y_pred)\n",
    "print(f'Test F1 score: {test_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e66f713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"clean_df (2).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7fc7edb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df.drop('Cancer', axis=1)\n",
    "y=df.Cancer\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aada51ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rdemoz/.local/lib/python3.9/site-packages/sklearn/impute/_iterative.py:825: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "imputer = IterativeImputer(max_iter = 3, random_state=0)\n",
    "X_train = imputer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89968e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rdemoz/.local/lib/python3.9/site-packages/sklearn/impute/_iterative.py:825: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "imputer = IterativeImputer(max_iter = 3, random_state=0)\n",
    "X_test = imputer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "69fadf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "X_train, y_train= smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1fdc869b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1545226/3453302362.py:14: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  keras_clf = KerasClassifier(build_fn=build_model, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras import layers, models\n",
    "def build_model(optimizer='adam'):\n",
    "    model = models.Sequential([\n",
    "        layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=[tf.keras.metrics.Recall()])\n",
    "    return model\n",
    "\n",
    "keras_clf = KerasClassifier(build_fn=build_model, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4fad27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
